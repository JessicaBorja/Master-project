project_path:  /mnt/ssd_shared/Users/Jessica/Documents/Proyecto_ssd/
data_path: ${project_path}/VREnv/data/
save_dir: ./hydra_outputs/${task}
model_name: full
task: pickup
euler_obs: true
img_size: 64
repeat_training: 1
viz_obs: False

# path to load affordance models either gripper_cam 
# or static_cam
save_replay_buffer: False
models_path: "${project_path}/vapo/trained_models/"
save_images: False

# Resume training
resume_training: False
resume_model_path: ${test_cfg.folder_name}

# tabletop_multiscene_static_sideview.ckpt 
# Static cam affordance model to detect the targets
target_search_aff:
  model_path: ${models_path}/tabletop_multiscene_static_sideview.ckpt  # static_centers_2-5_1_5_1_200px_epoch_13.ckpt
  img_size: 200
  hyperparameters:
    n_classes: 2
    hough_voting:
      skip_pixels: 2
      inlier_threshold: 0.7
      angle_discretization: 100
      inlier_distance: 10
      percentage_threshold: 0.3
      object_center_kernel_radius: 15
    centers_loss:
      weight: 5
    aff_loss:
      weight: 2
      dice_loss:
        add: True
        weight: 5
      ce_loss:
        weight: 1
        class_weights: [0.2, 0.8]
    optimizer:
      lr: 1e-5
      weight_decay: 1e-3
    unet_cfg:
      decoder_channels: [128, 64, 32]

#
target_search: "env"
# Define types of observation input to the RL agent
env_wrapper:
  gripper_cam:
    use_img: True
    use_depth: False
  static_cam:
    use_img: False
    use_depth: False
  use_pos: True
  history_length: 1
  skip_frames: 0
  img_size: ${img_size}
  use_aff_termination: False
  max_target_dist: 0.15

# Affordance configuration for RL agent observation inputs
affordance:
    static_cam:
      use: False
      model_path: ${models_path}/tabletop_multiscene_static_sideview.ckpt
      img_size: 200
      hough_voting:
        skip_pixels: 2
        inlier_threshold: 0.7
        angle_discretization: 100
        inlier_distance: 10
        percentage_threshold: 0.3
        object_center_kernel_radius: 10
      hyperparameters:
        n_classes: 2
        centers_loss:
          weight: 2.5
        aff_loss:
          weight: 1
          dice_loss:
            add: True
            weight: 5
          ce_loss:
            weight: 1
            class_weights: [0.2, 0.8]
        optimizer:
          lr: 1e-5
          weight_decay: 1e-3
        unet_cfg:
          decoder_channels: [128, 64, 32]
    gripper_cam:
      use: False  # Use affordance in observation
      use_distance: False
      densify_reward: False  # Use affordance to shape the reward function
      target_in_obs: False  # Add target detected by affordance into observation
      model_path: ${models_path}/tabletop_multiscene_gripper_labels.ckpt # tabletop_multiscene_gripper_sideview_2.ckpt  # gripper_centers_2-5_1_5_1_64px_epoch_40.ckpt
      hough_voting:
        skip_pixels: 2
        inlier_threshold: 0.7
        angle_discretization: 100
        inlier_distance: 10
        percentage_threshold: 0.3
        object_center_kernel_radius: 10
      hyperparameters:
        n_classes: 2
        centers_loss:
          weight: 2.5
        aff_loss:
          weight: 1
          dice_loss:
            add: True
            weight: 5
          ce_loss:
            weight: 1
            class_weights: [0.2, 0.8]
        optimizer:
          lr: 1e-5
          weight_decay: 1e-3
        unet_cfg:
          decoder_channels: [128, 64, 32]

hydra:
  run:
    dir: ${save_dir}/${now:%Y-%m-%d}/${now:%H-%M-%S}

defaults:
  - robot: panda
  - scene: tabletop_random
  - env: env_combined
  - env@eval_env: env_combined
  - camera_conf: tabletop
  - agent: default
  - test: test_tabletop
  - wandb_login: vapo_jess
  - transforms@affordance.transforms: aff_transforms
  - transforms@env_wrapper.transforms: rl_transforms
  - override hydra/hydra_logging: colorlog
  - override hydra/job_logging: colorlog